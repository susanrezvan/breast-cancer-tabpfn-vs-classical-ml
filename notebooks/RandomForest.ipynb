{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiEUNCtuGRTO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, confusion_matrix)\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tabpfn import TabPFNClassifier\n",
        "\n",
        "# === 1) Load data ===\n",
        "df = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\n",
        "\n",
        "# Drop unnecessary columns\n",
        "for col in [\"id\", \"Unnamed: 32\"]:\n",
        "    if col in df.columns:\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "\n",
        "# Features / Target\n",
        "X = df.drop(columns=[\"diagnosis\"])\n",
        "y = df[\"diagnosis\"]\n",
        "\n",
        "# Encode labels (M=1, B=0)\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# === 2) Train/Test Split (before feature selection to avoid leakage) ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# === 3) Mutual Information Feature Selection (fit ONLY on train) ===\n",
        "\n",
        "TOP_K = 15\n",
        "\n",
        "#y_train\n",
        "mi_scores = mutual_info_classif(X_train, y_train, random_state=42)\n",
        "mi_series = pd.Series(mi_scores, index=X_train.columns).sort_values(ascending=False)\n",
        "\n",
        "#  Top-K\n",
        "top_features = mi_series.head(TOP_K).index.tolist()\n",
        "\n",
        "print(\"\\n=== Top-{} Features by Mutual Information ===\".format(TOP_K))\n",
        "for i, (feat, score) in enumerate(mi_series.head(TOP_K).items(), start=1):\n",
        "    print(f\"{i:2d}. {feat:25s}  MI = {score:.4f}\")\n",
        "\n",
        "#MI\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=mi_series.head(TOP_K).values, y=mi_series.head(TOP_K).index, orient='h')\n",
        "plt.title(f\"Mutual Information (Top {TOP_K})\")\n",
        "plt.xlabel(\"MI Score\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# The selected data\n",
        "X_train_sel = X_train[top_features].copy()\n",
        "X_test_sel  = X_test[top_features].copy()\n",
        "\n",
        "# === 4) TabPFN Classifier\n",
        "clf = TabPFNClassifier(device=\"cpu\")\n",
        "clf.fit(X_train_sel, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test_sel)\n",
        "y_proba = clf.predict_proba(X_test_sel)[:, 1]\n",
        "\n",
        "# === 5) Metrics ===\n",
        "acc  = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec  = recall_score(y_test, y_pred)\n",
        "f1   = f1_score(y_test, y_pred)\n",
        "auc  = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(\"\\n=== TabPFN + MI (Top-{}) Metrics ===\".format(TOP_K))\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall   : {rec:.4f}\")\n",
        "print(f\"F1 Score : {f1:.4f}\")\n",
        "print(f\"ROC AUC  : {auc:.4f}\")\n",
        "\n",
        "# === 6) Confusion Matrix ===\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(3.2, 3.2))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", cbar=False,\n",
        "            xticklabels=['Benign','Malignant'], yticklabels=['Benign','Malignant'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"TabPFN (Top-{} via Mutual Information)\".format(TOP_K))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Download + Load data\n",
        "\n",
        "path = kagglehub.dataset_download(\"uciml/breast-cancer-wisconsin-data\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "print(\"Files:\", os.listdir(path))\n",
        "\n",
        "# data.cs\n",
        "df = pd.read_csv(os.path.join(path, \"data.csv\"))\n",
        "\n",
        "# Clean\n",
        "\n",
        "for col in [\"id\", \"Unnamed: 32\"]:\n",
        "    if col in df.columns:\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "\n",
        "# Target / Features\n",
        "y = df[\"diagnosis\"]                # 'M' or 'B'\n",
        "X = df.drop(columns=[\"diagnosis\"])\n",
        "\n",
        "# B=0, M=1\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# 4) Split (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Preprocess\n",
        "num_cols = X_train.columns.tolist()\n",
        "numeric_pre = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "])\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[(\"num\", numeric_pre, num_cols)],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "#  RandomForest (no Feature Selection)\n",
        "rf_base = Pipeline(steps=[\n",
        "    (\"prep\", preprocess),\n",
        "    (\"rf\", RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        max_features=\"sqrt\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "rf_base.fit(X_train, y_train)\n",
        "y_pred_base  = rf_base.predict(X_test)\n",
        "y_proba_base = rf_base.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\n=== RandomForest (no FS) ===\")\n",
        "print(\"Accuracy :\", accuracy_score(y_test, y_pred_base))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_base))\n",
        "print(\"Recall   :\", recall_score(y_test, y_pred_base))\n",
        "print(\"F1-Score :\", f1_score(y_test, y_pred_base))\n",
        "print(\"ROC-AUC  :\", roc_auc_score(y_test, y_proba_base))\n",
        "print(\"\\nClassification Report:\\n\",\n",
        "      classification_report(y_test, y_pred_base, target_names=[\"Benign\",\"Malignant\"]))\n",
        "\n",
        "\n",
        "# RandomForest + Feature Selection (Mutual Information)\n",
        "rf_fs = Pipeline(steps=[\n",
        "    (\"prep\", preprocess),\n",
        "    (\"kbest\", SelectKBest(score_func=mutual_info_classif, k=10)),\n",
        "    (\"rf\", RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        max_features=\"sqrt\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "rf_fs.fit(X_train, y_train)\n",
        "y_pred_fs  = rf_fs.predict(X_test)\n",
        "y_proba_fs = rf_fs.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\n=== RandomForest + Feature Selection (Mutual Info) ===\")\n",
        "print(\"Accuracy :\", accuracy_score(y_test, y_pred_fs))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_fs))\n",
        "print(\"Recall   :\", recall_score(y_test, y_pred_fs))\n",
        "print(\"F1-Score :\", f1_score(y_test, y_pred_fs))\n",
        "print(\"ROC-AUC  :\", roc_auc_score(y_test, y_proba_fs))\n",
        "print(\"\\nClassification Report:\\n\",\n",
        "      classification_report(y_test, y_pred_fs, target_names=[\"Benign\",\"Malignant\"]))\n",
        "\n",
        "\n",
        "\n",
        "# Confusion Matrix - no Feature Selection\n",
        "cm_base = confusion_matrix(y_test, y_pred_base)\n",
        "\n",
        "# Confusion Matrix - with Feature Selection\n",
        "cm_fs = confusion_matrix(y_test, y_pred_fs)\n",
        "\n",
        "# fig\n",
        "fig, axes = plt.subplots(1, 2, figsize=(6,3))\n",
        "\n",
        "# no FS\n",
        "sns.heatmap(cm_base, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[0])\n",
        "axes[0].set_title(\"RandomForest \")\n",
        "axes[0].set_xlabel(\"Predicted\")\n",
        "axes[0].set_ylabel(\"Actual\")\n",
        "\n",
        "# with FS (Mutual Info)\n",
        "sns.heatmap(cm_fs, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[1])\n",
        "axes[1].set_title(\"RandomForest + FS (MI)\")\n",
        "axes[1].set_xlabel(\"Predicted\")\n",
        "axes[1].set_ylabel(\"Actual\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "try:\n",
        "    from sklearn import set_config\n",
        "    set_config(transform_output=\"pandas\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Extract the names of the selected features (after SelectKBest)\n",
        "kbest_step = rf_fs.named_steps[\"kbest\"]\n",
        "selected_mask = kbest_step.get_support()\n",
        "selected_features = np.array(num_cols)[selected_mask]\n",
        "\n",
        "rf_model = rf_fs.named_steps[\"rf\"]\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "feat_imp = pd.DataFrame({\"feature\": selected_features,\n",
        "                         \"importance\": importances}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "print(\"\\nTop features (RF + MI):\")\n",
        "print(feat_imp.head(10))\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "sns.barplot(x=\"importance\", y=\"feature\", data=feat_imp.head(10))\n",
        "plt.title(\"Top Features (RF + Mutual Info)\")\n",
        "plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "Ebt63gyvGfI8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}